bases:
- "{{ requiredEnv "MYDIR" }}/helmfile/envs.yaml"
---
repositories:
- name: banzaicloud  # thanos, src: https://github.com/banzaicloud/banzai-charts
  url: "https://kubernetes-charts.banzaicloud.com"
# - https://github.com/timescale/promscale/tree/master/helm-chart
# - https://github.com/timescale/timescaledb-kubernetes
# - https://github.com/timescale/tobs
- name: timescale
  url: "https://charts.timescale.com"
- name: bitnami  # memcached, https://github.com/bitnami/charts
  url: "https://charts.bitnami.com/bitnami"
- name: cortex  # https://github.com/cortexproject/cortex-helm-chart
  url: "https://cortexproject.github.io/cortex-helm-chart"
- name: grafana  # https://github.com/grafana/helm-charts
  url: "https://grafana.github.io/helm-charts"

templates:
  cortex:
    values:
    - &cortexEtcdKvStore
      store: etcd
      etcd:
        endpoints: ["etcd.{{ .Values.namespaces.storage }}.svc:2379"]
        tls_enabled: false
        tls_insecure_skip_verify: false
    - &cortexS3
      endpoint: "{{ .Values.releases.minio }}.{{ .Values.namespaces.storage }}.svc:{{ .Values.minio.servicePort }}"
      access_key_id: {{ .Values.minio.accessKey | quote }}
      secret_access_key: {{ .Values.minio.secretKey | quote }}
      insecure: true
      signature_version: v2
    - &cortexBlockKvStore
      kvstore:
        <<: *cortexEtcdKvStore
        prefix: "cortex/collectors/"
  grafana:
    values:
    - &grafanaRedis
      endpoint: "{{ .Values.releases.redis }}-haproxy.{{ .Values.namespaces.storage }}.svc:{{ .Values.redis.ports.readwrite }}"
      password: {{ .Values.redis.password | quote }}
    - &etcdKvStore
      store: etcd
      etcd:
        endpoints: ["etcd.{{ .Values.namespaces.storage }}.svc:2379"]
    - &grafanaS3
      endpoint: "{{ .Values.releases.minio }}.{{ .Values.namespaces.storage }}.svc:{{ .Values.minio.servicePort }}"
      access_key_id: {{ .Values.minio.accessKey | quote }}
      secret_access_key: {{ .Values.minio.secretKey | quote }}
      s3forcepathstyle: true
      insecure: true

releases:
- name: {{ .Values.releases.thanos }}
  namespace: {{ .Values.namespaces.monitoring }}
  chart: banzaicloud/thanos
  installed: {{ and .Values.enables.monitoring .Values.enables.minio (not .Values.enables.cortex) }}
  needs:
  - {{ .Values.namespaces.storage }}/{{ .Values.releases.minio }}
  values:
  - fullnameOverride: {{ .Values.releases.thanos | quote }}
    objstoreSecretOverride: {{ .Values.thanosObjstoreConfig.secret | quote }}
    image:
      tag: 'v{{ .Values.versions.images.thanos }}'
    compact:
      retentionResolutionRaw: 3d
      retentionResolution5m: 16d
      retentionResolution1h: 28d
    objstore:
      type: S3
      config:
        bucket: {{ .Values.minio.defaultBucket | quote }}
        endpoint: "{{ .Values.releases.minio }}.{{ .Values.namespaces.storage }}.svc:{{ .Values.minio.servicePort }}"
        access_key: {{ .Values.minio.accessKey | quote }}
        secret_key: {{ .Values.minio.secretKey | quote }}
        insecure: true
        signature_version2: true
    query:
      replicaLabels:
      - prometheus_replica  # server-scoped
      #- prometheus  # cluster-scoped

{{- range (list "" "-index" "-metadata") }}
- name: {{ $.Values.releases.cortex }}-memcached-blocks{{ . }}
  namespace: {{ $.Values.namespaces.monitoring }}
  chart: bitnami/memcached
  installed: {{ and $.Values.enables.monitoring $.Values.enables.minio $.Values.enables.cortex }}
  version: {{ $.Values.versions.charts.memcached }}
  needs:
  - {{ $.Values.namespaces.storage }}/{{ $.Values.releases.openebs }}
  values:
  - architecture: high-availability
    replicaCount: {{ default 1 (env "MEMCACHED_COUNT") }}
    image:
      tag: {{ $.Values.versions.images.memcached }}
{{- end }}

- name: {{ .Values.releases.cortex }}
  namespace: {{ .Values.namespaces.monitoring }}
  chart: "{{ .Values.chartBases.cortex }}"
  installed: {{ and .Values.enables.monitoring .Values.enables.minio .Values.enables.cortex }}
  skipDeps: true
  needs:
  - {{ .Values.namespaces.storage }}/{{ .Values.releases.minio }}
{{- if .Values.enables.cortex }}
  hooks:
  - events: ["presync"]
    command: "/bin/sh"
    args:
    - "-xec"
    - |
      kubectl get ns {{ .Values.namespaces.monitoring }} || kubectl create ns {{ .Values.namespaces.monitoring }}
      kubectl -n {{ .Values.namespaces.monitoring }} apply -f- <<EOF
      kind: ConfigMap
      apiVersion: v1
      metadata:
        name: {{ .Values.cortex.fallbackConfig.configMap }}
      data:
        {{ .Values.cortex.fallbackConfig.subPath }}: |
          receivers:
          - name: blackhole
          route:
            receiver: blackhole
      EOF
{{- end }}
  values:
  - images:
      tag: v{{ .Values.versions.images.cortex }}
    alertmanager:
      extraVolumes:
      - name: alertmanager-fallback
        configMap:
          name: {{ .Values.cortex.fallbackConfig.configMap }}
          optional: false
      - name: tmp
        emptyDir: {}
      extraVolumeMounts:
      - mountPath: {{ .Values.cortex.fallbackConfig.mountPath }}
        name: alertmanager-fallback
        readOnly: true
      - mountPath: /tmp
        name: tmp
    config:  # ref: https://github.com/cortexproject/cortex/blob/master/docs/configuration/config-file-reference.md
      chunk_store:
        chunk_cache_config:  # store.chunks-cache
          redis:
            <<: *grafanaRedis
            db: 10
        write_dedupe_cache_config:  # store.index-cache-write
          redis:
            <<: *grafanaRedis
            db: 9
      query_range:
        cache_results: true
        results_cache:
          cache:  # frontend.cache
            redis:
              <<: *grafanaRedis
              db: 11
      storage:
        engine: blocks
        index_queries_cache_config:  # store.index-cache-read
          redis:
            <<: *grafanaRedis
            db: 8
      blocks_storage:
        bucket_store:
          bucket_index:
            enabled: true
          sync_dir: /data/tsdb-sync
          chunks_cache:
            backend: memcached
            memcached:
              addresses: "dns+{{ .Values.releases.cortex }}-memcached-blocks.{{ .Values.namespaces.monitoring }}.svc:11211"
              #host: "{{ .Values.releases.cortex }}-memcached-blocks.{{ .Values.namespaces.monitoring }}.svc:11211"
{{/*
            backend: redis
            redis:
              <<: *grafanaRedis
              db: 5
*/}}
          index_cache:
            backend: memcached
            memcached:
              addresses: "dns+{{ .Values.releases.cortex }}-memcached-blocks-index.{{ .Values.namespaces.monitoring }}.svc:11211"
              #host: "{{ .Values.releases.cortex }}-memcached-blocks-index.{{ .Values.namespaces.monitoring }}.svc:11211"
{{/*
            backend: redis
            redis:
              <<: *grafanaRedis
              db: 6
*/}}
          metadata_cache:
            backend: memcached
            memcached:
              addresses: "dns+{{ .Values.releases.cortex }}-memcached-blocks-metadata.{{ .Values.namespaces.monitoring }}.svc:11211"
              #host: "{{ .Values.releases.cortex }}-memcached-blocks-metadata.{{ .Values.namespaces.monitoring }}.svc:11211"
{{/*
            backend: redis
            redis:
              <<: *grafanaRedis
              db: 7
*/}}
        tsdb:
          dir: /data/tsdb
        backend: s3
        s3:
          <<: *cortexS3
          bucket_name: {{ .Values.cortex.buckets.blocks | quote }}
      store_gateway:
        sharding_enabled: true
        sharding_ring:
          <<: *cortexBlockKvStore
      distributor:
        ha_tracker:
          enable_ha_tracker: true
          kvstore:
            <<: *cortexEtcdKvStore
            prefix: "cortex/ha-tracker/"
        ring:
          <<: *cortexBlockKvStore
      ingester:
        lifecycler:
          ring:
            <<: *cortexBlockKvStore
      compactor:
        sharding_ring:
          <<: *cortexBlockKvStore
      ruler:
        enable_api: true
        enable_sharding: true
        enable_alertmanager_v2: true
        ring:
          kvstore:
            <<: *cortexEtcdKvStore
            prefix: "cortex/rulers/"
      alertmanager:
        enable_api: true
        sharding_enabled: true
        fallback_config_file: {{ .Values.cortex.fallbackConfig.mountPath }}/{{ .Values.cortex.fallbackConfig.subPath }}
        sharding_ring:
          kvstore:
            <<: *cortexEtcdKvStore
            prefix: "cortex/alertmanagers/"
{{- range (list "alertmanager" "ruler") }}
      {{ . }}_storage:
        backend: s3
        s3:
          <<: *cortexS3
          bucket_name: {{ $.Values.cortex.buckets.notify | quote }}
{{- end }}
  -
{{- range (list "alertmanager" "nginx" "distributor" "ingester" "ruler" "querier" "query_frontend" "table_manager" "configs" "store_gateway" "compactor") }}
    {{ . }}:
      #replicas: 3
      statefulSet:
        enabled: true
      #serviceMonitor:
      #  enabled: true
{{- end }}

- name: {{ .Values.releases.loki }}
  namespace: {{ .Values.namespaces.monitoring }}
  chart: grafana/loki-distributed
  installed: {{ and .Values.enables.monitoring .Values.enables.minio }}
  needs:
  - {{ .Values.namespaces.storage }}/{{ .Values.releases.cassandra }}
  - {{ .Values.namespaces.storage }}/{{ .Values.releases.etcd }}
  - {{ .Values.namespaces.storage }}/{{ .Values.releases.minio }}
  - {{ .Values.namespaces.storage }}/{{ .Values.releases.redis }}
  values:
  - fullnameOverride: loki
{{- range (list "distributor" "ingester" "querier" "queryFrontend" "gateway") }}
    {{ . }}:
      replicas: 1
{{- end }}
    tableManager:
      enabled: true
    compactor:
      enabled: false
    ruler:
      enabled: true
    loki:
      # https://grafana.com/docs/loki/latest/configuration/
      config: |
        auth_enabled: false
        storage_config:
          aws:
            #<<: *grafanaS3
            endpoint: "{{ .Values.releases.minio }}.{{ .Values.namespaces.storage }}.svc:{{ .Values.minio.servicePort }}"
            access_key_id: {{ .Values.minio.accessKey | quote }}
            secret_access_key: {{ .Values.minio.secretKey | quote }}
            s3forcepathstyle: true
            insecure: true
            bucketnames: {{ .Values.loki.buckets.chunks | quote }}
          cassandra:
            addresses: {{ .Values.releases.cassandra }}-client.{{ .Values.namespaces.storage }}.svc
            auth: true
            keyspace: loki
            consistency: LOCAL_QUORUM
            replication_factor: 1
          index_queries_cache_config:
            redis:
              #<<: *grafanaRedis
              endpoint: "{{ .Values.releases.redis }}-haproxy.{{ .Values.namespaces.storage }}.svc:{{ .Values.redis.ports.readwrite }}"
              password: {{ .Values.redis.password | quote }}
              db: 12
        schema_config:
          configs:
          - from: 2020-09-07
            store: cassandra
            object_store: s3
            schema: v11
            index:
              prefix: loki_index_
              period: 24h
            #chunks:
            #  prefix: loki_chunk_
            #  period: 24h
        limits_config:
          enforce_metric_name: false
          ingestion_rate_mb: 128
          reject_old_samples: true
          reject_old_samples_max_age: 168h
          max_cache_freshness_per_query: 10m
        server:
          http_listen_port: {{ .Values.loki.ports.http }}
        distributor:
          ring:
            kvstore:
              #<<: *etcdKvStore
              store: etcd
              etcd:
                endpoints: ["etcd.{{ .Values.namespaces.storage }}.svc:2379"]
              prefix: "loki/collectors/"
        ingester:
          chunk_idle_period: 30m
          chunk_block_size: 262144
          chunk_encoding: snappy
          chunk_retain_period: 1m
          max_transfer_retries: 0
          lifecycler:
            final_sleep: 0s
            ring:
              replication_factor: 1
              kvstore:
                #<<: *etcdKvStore
                store: etcd
                etcd:
                  endpoints: ["etcd.{{ .Values.namespaces.storage }}.svc:2379"]
                prefix: "loki/collectors/"
        ruler:
          enable_api: true
          ring:
            kvstore:
              #<<: *etcdKvStore
              store: etcd
              etcd:
                endpoints: ["etcd.{{ .Values.namespaces.storage }}.svc:2379"]
              prefix: "loki/rulers/"
          storage:
            type: s3
            s3:
              #<<: *grafanaS3
              endpoint: "{{ .Values.releases.minio }}.{{ .Values.namespaces.storage }}.svc:{{ .Values.minio.servicePort }}"
              access_key_id: {{ .Values.minio.accessKey | quote }}
              secret_access_key: {{ .Values.minio.secretKey | quote }}
              s3forcepathstyle: true
              insecure: true
              bucketnames: {{ .Values.loki.buckets.notify | quote }}
        chunk_store_config:
          max_look_back_period: 0s
          chunk_cache_config:
            redis:
              #<<: *grafanaRedis
              endpoint: "{{ .Values.releases.redis }}-haproxy.{{ .Values.namespaces.storage }}.svc:{{ .Values.redis.ports.readwrite }}"
              password: {{ .Values.redis.password | quote }}
              db: 14
          write_dedupe_cache_config:
            redis:
              #<<: *grafanaRedis
              endpoint: "{{ .Values.releases.redis }}-haproxy.{{ .Values.namespaces.storage }}.svc:{{ .Values.redis.ports.readwrite }}"
              password: {{ .Values.redis.password | quote }}
              db: 15
        table_manager:
          retention_deletes_enabled: false
          retention_period: 0s
        query_range:
          align_queries_with_step: true
          max_retries: 5
          split_queries_by_interval: 15m
          cache_results: true
          results_cache:
            cache:
              redis:
                #<<: *grafanaRedis
                endpoint: "{{ .Values.releases.redis }}-haproxy.{{ .Values.namespaces.storage }}.svc:{{ .Values.redis.ports.readwrite }}"
                password: {{ .Values.redis.password | quote }}
                db: 13
        frontend_worker:
          frontend_address: "loki-query-frontend:{{ .Values.loki.ports.grpc }}"
        frontend:
          log_queries_longer_than: 5s
          compress_responses: true
          tail_proxy_url: "http://loki-querier:{{ .Values.loki.ports.http }}"

# requires non-free timescale-licensed addon to timescaledb.so
- name: {{ .Values.releases.promscale }}
  namespace: {{ .Values.namespaces.storage }}
  #chart: timescale/promscale
  chart: "{{ .Values.chartBases.promscale }}"
  installed: {{ and .Values.enables.storage .Values.enables.monitoring }}
  needs:
  - {{ .Values.namespaces.storage }}/{{ .Values.releases.patroni }}
  values:
  - connection:
      password:
        timescaleDBSuperUserKey: password-superuser
        secretTemplate: {{ .Values.releases.patroni | quote }}
      host:
        nameTemplate: '{{ .Values.releases.patroni }}.{{ .Values.namespaces.storage }}.svc'
    service:
      loadBalancer:
        enabled: false

- name: {{ .Values.releases.kubePromStack }}
  namespace: {{ .Values.namespaces.monitoring }}
  chart: prometheus-community/kube-prometheus-stack
  {{/* version: {{ .Values.versions.charts.kubePromStack }} */}}
  installed: {{ .Values.enables.monitoring }}
  needs:
  - {{ .Values.namespaces.monitoring }}/{{ .Values.releases.cortex }}
  - {{ .Values.namespaces.monitoring }}/{{ .Values.releases.thanos }}
  - {{ .Values.namespaces.storage }}/{{ .Values.releases.promscale }}
  values:
  - fullnameOverride: {{ .Values.releases.kubePromStack | quote }}
    prometheus:
      prometheusSpec:
        podMetadata:
          labels:
            prometheus: self
        #serviceMonitorNamespaceSelector: {}
        serviceMonitorSelector:
          matchLabels: {}  # match *ALL* ServiceMonitors on an *empty* set of labels
        #podMonitorNamespaceSelector: {}
        podMonitorSelector:
          matchLabels: {}  # match *ALL* PodMonitors on an *empty* set of labels
        logLevel: debug
        retention: 3h
{{- if .Values.enables.promscale }}
        remoteRead:
        - url: "http://promscale-connector.{{ .Values.namespaces.storage }}.svc:9201/read"
          readRecent: true
{{- end }}
{{- if or .Values.enables.cortex .Values.enables.promscale }}
        remoteWrite:
{{- if .Values.enables.promscale }}
        - url: "http://promscale-connector.{{ .Values.namespaces.storage }}.svc:9201/write"
{{- end }}
{{- if .Values.enables.cortex }}
        - url: "http://cortex-distributor.{{ .Values.namespaces.monitoring }}.svc:8080/api/v1/push"
{{- end }}
{{- end }}
        secrets:  # mounted under /etc/prometheus/secrets/<secret_name>/<key>
        - {{ .Values.thanosSidecarMTLSSecret }}
        thanos:  # https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#thanosspec
          image: "quay.io/thanos/thanos:v{{ .Values.versions.images.thanos }}"
          version: v{{ .Values.versions.images.thanos }}
          objectStorageConfig:
            key: {{ .Values.thanosObjstoreConfig.filename }}
            name: {{ .Values.thanosObjstoreConfig.secret }}
        #  grpcServerTlsConfig:
        #    caFile: /etc/prometheus/secrets/{{ .Values.thanosSidecarMTLSSecret }}/ca.crt
        #    certFile: /etc/prometheus/secrets/{{ .Values.thanosSidecarMTLSSecret }}/tls.crt
        #    keyFile: /etc/prometheus/secrets/{{ .Values.thanosSidecarMTLSSecret }}/tls.key
        #containers:  # https://github.com/prometheus-operator/prometheus-operator/issues/3322#issuecomment-655369312
        #- name: thanos-sidecar
        #  volumeMounts:
        #  - mountPath: /etc/prometheus/secrets/{{ .Values.thanosSidecarMTLSSecret }}
        #    readOnly: true
        #    name: secret-{{ .Values.thanosSidecarMTLSSecret }}
    grafana:
      image:
        repository: docker.io/grafana/grafana
        tag: {{ .Values.versions.images.grafana }}
      sidecar:
        datasources:
          defaultDatasourceEnabled: false
      #plugins:
      #- camptocamp-prometheus-alertmanager-datasource
      grafana.ini:
        panels:
          enable_alpha: true
        feature_toggles:
          enable: ngalert
      additionalDataSources:
      - type: loki
        name: Loki
        access: proxy
        url: "http://loki-query-frontend:{{ .Values.loki.ports.http }}"
      - type: prometheus
        access: proxy
        isDefault: true
{{- if not .Values.enables.cortex }}
        name: Thanos
        url: "http://thanos-query-http.{{ .Values.namespaces.monitoring }}.svc:10902/"
{{- else }}
        name: Cortex
        #url: "http://cortex-query-frontend.{{ .Values.namespaces.monitoring }}.svc:8080/prometheus"
        url: "http://cortex-nginx.{{ .Values.namespaces.monitoring }}.svc/api/prom"
      - type: alertmanager
        access: proxy
        name: Cortex-Alertmanager
        #url: "http://cortex-alertmanager.{{ .Values.namespaces.monitoring }}.svc:8080/api/prom"
        url: "http://cortex-nginx.{{ .Values.namespaces.monitoring }}.svc/api/prom"
{{- end }}

# doc: (use autoscaling/v2beta[12] HorizontalPodAutoscaler)
# - ref: https://github.com/kubernetes-sigs/prometheus-adapter/blob/master/docs/config.md
# - tut: https://github.com/kubernetes-sigs/prometheus-adapter/blob/master/docs/config-walkthrough.md
- name: {{ .Values.releases.prometheusAdapter }}
  namespace: {{ .Values.namespaces.monitoring }}
  chart: prometheus-community/prometheus-adapter
  installed: {{ .Values.enables.monitoring }}
  needs:
  - {{ .Values.namespaces.monitoring }}/{{ .Values.releases.kubePromStack }}
  values:
  - image:
      repository: k8s.gcr.io/prometheus-adapter/prometheus-adapter
      tag: v{{ .Values.versions.images.prometheusAdapter }}
    prometheus:
      url: "http://{{ .Values.releases.kubePromStack }}-prometheus.{{ .Values.namespaces.monitoring }}.svc"
    rules: {}
