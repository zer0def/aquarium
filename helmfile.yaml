{{- $helmTimeout := default 86400 (env "HELM_TIMEOUT") -}}

{{- $namespaces := dict "monitoring" (default "monitoring" (env "NAMESPACES_MONITORING")) "network" (default "network" (env "NAMESPACES_NETWORK")) "serverless" (default "serverless" (env "NAMESPACES_SERVERLESS")) "serverlessFunctions" (default "serverless-functions" (env "NAMESPACES_SERVERLESS_FUNCTIONS")) "storage" (default "storage" (env "NAMESPACES_STORAGE")) -}}
{{- $releases := dict "certManager" (default "cert-manager" (env "RELEASES_CERT_MANAGER")) "harbor" (default "harbor" (env "RELEASES_HARBOR")) "istio" (dict "old" (default "istio" (env "RELEASES_ISTIO")) "init" (default "istio-init" (env "RELEASES_ISTIO_INIT")) "base" (default "istio-base" (env "RELEASES_ISTIO_BASE")) "control" (default "istio-control" (env "RELEASES_ISTIO_CONTROL")) "gateway" (dict "egress" (default "istio-egress" (env "RELEASES_ISTIO_GATEWAY_EGRESS")) "ingress" (default "istio-ingress" (env "RELEASES_ISTIO_GATEWAY_INGRESS"))) "policy" (default "istio-policy" (env "RELEASES_ISTIO_POLICY")) "telemetry" (dict "grafana" (default "istio-grafana" (env "RELEASES_ISTIO_TELEMETRY_GRAFANA")) "kiali" (default "istio-kiali" (env "RELEASES_ISTIO_TELEMETRY_KIALI")) "prometheusOperator" (default "istio-prometheus-operator" (env "RELEASES_ISTIO_TELEMETRY_PROMETHEUS_OPERATOR")) "tracing" (default "istio-tracing" (env "RELEASES_ISTIO_TELEMETRY_TRACING")))) "jaegerOperator" (default "jaeger-operator" (env "RELEASES_JAEGER_OPERATOR")) "kubeless" (default "kubeless" (env "RELEASES_KUBELESS")) "minio" (default "minio" (env "RELEASES_MINIO")) "openebs" (default "openebs" (env "RELEASES_OPENEBS")) "patroni" (default "patroni" (env "RELEASES_PATRONI")) "prometheusAdapter" (default "prometheus-adapter" (env "RELEASES_PROMETHEUS_ADAPTER")) "prometheusOperator" (default "prometheus-operator" (env "RELEASES_PROMETHEUS_OPERATOR")) "redis" (default "redis" (env "RELEASES_REDIS")) "thanos" (default "thanos" (env "RELEASES_THANOS")) -}}
{{- $versions := dict "certManager" (default "0.15.1" (env "VERSIONS_CERT_MANAGER")) "harbor" (default "2.0.1" (env "VERSIONS_HARBOR")) "istio" (default "1.6.5" (env "VERSIONS_ISTIO")) "jaeger" (default "1.18.1" (env "VERSIONS_JAEGER")) "openebs" (default "1.11.0" (env "VERSIONS_OPENEBS") | quote) "openebsNdm" (default "0.6.0" (env "VERSIONS_OPENEBS_NDM")) "prometheusAdapter" (default "0.7.0" (env "VERSIONS_PROMETHEUS_ADAPTER")) "thanos" (default "0.14.0" (env "VERSIONS_THANOS")) -}}

{{- $istioChartManifestBase := "./istio/manifests/charts" -}}

{{- $harbor := dict "adminPassword" (default "Harbor12345" (env "HARBOR_ADMIN_PASSWORD")) "coreHostname" (default "core.harbor.domain" (env "HARBOR_CORE_HOSTNAME")) "httpNodePort" (default "30002" (env "HARBOR_HTTP_NODEPORT")) "chartVersion" (default "1.4.0" (env "CHART_VERSIONS_HARBOR")) "db" (dict "core" (dict "name" (default "harbor_core" (env "HARBOR_DB_CORE_NAME")) "user" (default "harbor_core" (env "HARBOR_DB_CORE_USER")) "pass" (default "harbor_core" (env "HARBOR_DB_CORE_PASS"))) "clair" (dict "name" (default "harbor_clair" (env "HARBOR_DB_CLAIR_NAME")) "user" (default "harbor_clair" (env "HARBOR_DB_CLAIR_USER")) "pass" (default "harbor_clair" (env "HARBOR_DB_CLAIR_PASS"))) "notaryServer" (dict "name" (default "harbor_notary_server" (env "HARBOR_DB_NOTARY_SERVER_NAME")) "user" (default "harbor_notary_server" (env "HARBOR_DB_NOTARY_SERVER_USER")) "pass" (default "harbor_notary_server" (env "HARBOR_DB_NOTARY_SERVER_PASS"))) "notarySigner" (dict "name" (default "harbor_notary_signer" (env "HARBOR_DB_NOTARY_SIGNER_NAME")) "user" (default "harbor_notary_signer" (env "HARBOR_DB_NOTARY_SIGNER_USER")) "pass" (default "harbor_notary_signer" (env "HARBOR_DB_NOTARY_SIGNER_PASS")))) -}}
{{- $minio := dict "accessKey" (default "AKIAIOSFODNN7EXAMPLE" (env "MINIO_ACCESS_KEY")) "secretKey" (default "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY" (env "MINIO_SECRET_KEY")) "servicePort" (default 9000 (env "MINIO_SVC_PORT")) "defaultBucket" (default "minio-bucket" (env "MINIO_DEFAULT_BUCKET")) -}}

{{- $openebsOmitLoopDevs := default "" (env "OPENEBS_OMIT_LOOPDEVS") -}}
{{- if $openebsOmitLoopDevs -}}
  {{- $openebsOmitLoopDevs = printf ",%s" $openebsOmitLoopDevs -}}
{{- end -}}

{{- $redisPassword := default "redis" (env "REDIS_PASSWORD") -}}
{{- $thanosObjstoreConfig := dict "secret" (default "thanos-objstore-config" (env "THANOS_OBJSTORE_CONFIG_SECRET")) "filename" (default "object-store.yaml" (env "THANOS_OBJSTORE_CONFIG_FILENAME")) -}}

repositories:
- name: stable
  url: https://kubernetes-charts.storage.googleapis.com
- name: incubator
  url: https://kubernetes-charts-incubator.storage.googleapis.com
- name: banzaicloud  # thanos, src: https://github.com/banzaicloud/banzai-charts
  url: https://kubernetes-charts.banzaicloud.com
- name: jaegertracing  # jaeger, src: https://github.com/jaegertracing/helm-charts
  url: https://jaegertracing.github.io/helm-charts
#- name: openebs  # deprecated
#  url: https://openebs.github.io/charts
- name: harbor  # harbor, src: https://github.com/goharbor/harbor-helm
  url: https://helm.goharbor.io
- name: nginx  # ref: https://github.com/nginxinc/kubernetes-ingress/blob/master/docs/nginx-ingress-controllers.md#differences-between-nginxinckubernetes-ingress-and-kubernetesingress-nginx-ingress-controllers
  url: https://helm.nginx.com/stable
- name: jetstack  # cert-manager
  url: https://charts.jetstack.io
- name: rancher
  url: https://releases.rancher.com/server-charts/latest
- name: rook
  url: https://charts.rook.io/release
- name: yugabyte
  url: https://charts.yugabyte.com
{{- if semverCompare "<1.6" $versions.istio }}
- name: istio
  url: https://storage.googleapis.com/istio-release/releases/{{ $versions.istio }}/charts
{{- end }}

helmDefaults:
  wait: true
  timeout: {{ $helmTimeout }}
  tillerless: false

#bases: {}
#helmFiles:
#- path: postgres-operator-helmfile.yaml
#- path: rancher-helmfile.yaml

templates:
  istio:
    values:
    - global: &istioGlobal
        hub: docker.io/istio
        tag: {{ $versions.istio }}
        istioNamespace: {{ $namespaces.network }}
        telemetryNamespace: {{ $namespaces.network }}
        prometheusNamespace: {{ $namespaces.network }}
        policyNamespace: {{ $namespaces.network }}
        configRootNamespace: {{ $namespaces.network }}
        meshExpansion:
          enabled: true
      control: &istioControl
        disablePolicyChecks: false
        mtls:
          enabled: true
        outboundTrafficPolicy:
          mode: ALLOW_ANY
        proxy:
          accessLogFile: /dev/stdout
        sds:
          enabled: true
          udsPath: "unix:/var/run/sds/uds_path"
      gateways:
        istio-ingressgateway: &istioIngress
          type: NodePort
        istio-egressgateway: &istioEgress
          type: NodePort
    - &istioOldCertManager
      certmanager:
        enabled: true
    - &istioKiali
      kiali:
        enabled: true
        createDemoSecret: true
        dashboard:
          grafanaURL: "http://grafana.{{ $namespaces.network }}.svc:3000"
          jaegerURL: "http://{{ $releases.jaegerOperator }}-jaeger-query.{{ $namespaces.network }}.svc:16686"
    - &istioMixer
      mixer:
        # istio-policy
        policy:
          enabled: true
        # istio-telemetry/mixer-telemetry
        adapters:
          stdio:
            enabled: true
        telemetry:
          enabled: true
  harbor:
    values:
    - component: &harborVersion
        image:
          tag: v{{ $versions.harbor }}
  openebs:
    values:
    - disabledComponent: &openebsLVP
        enabled: false
        replicas: 0
      openebsTag: &openebsTag
        imageTag: {{ $versions.openebs }}
      openebsNdmTag: &openebsNdmTag
        imageTag: {{ $versions.openebsNdm }}

releases:
# network components
- name: {{ $releases.jaegerOperator }}
  namespace: {{ $namespaces.network }}
  chart: jaegertracing/jaeger-operator
  values:
  - fullnameOverride: {{ $releases.jaegerOperator | quote }}
    image:
      tag: {{ $versions.jaeger }}
    jaeger:
      create: true
      spec:  # https://www.jaegertracing.io/docs/1.16/operator/
        strategy: allInOne
        ingress:
          enabled: false
    # https://github.com/jaegertracing/jaeger-operator/issues/791
    rbac:
      clusterRole: true
{{- if semverCompare "<1.6" $versions.istio }}
- name: {{ $releases.istio.init }}
  namespace: {{ $namespaces.network }}
  chart: istio/istio-init
  values:
  - *istioOldCertManager
- name: {{ $releases.istio.old }}
  namespace: {{ $namespaces.network }}
  chart: istio/istio
  needs:
  - {{ $namespaces.network }}/{{ $releases.istio.init }}
  - {{ $namespaces.network }}/{{ $releases.jaegerOperator }}
  hooks:
  - events: ["presync"]
    command: "/bin/sh"
    args: ["-xec", "kubectl -n {{ $namespaces.network }} wait --for condition=complete --timeout {{ $helmTimeout }}s job --all"]
  values:
  - fullnameOverride: {{ $releases.istio.old | quote }}
    global:
      <<: *istioGlobal
      <<: *istioControl
    <<: *istioOldCertManager
    <<: *istioKiali
    <<: *istioMixer
    gateways:
      istio-ingressgateway:
        <<: *istioIngress
        sds:
          enabled: true
      istio-egressgateway:
        <<: *istioEgress
        enabled: true
    # === removed in 1.6 ===
    nodeagent:  # part of istio-proxy
      enabled: true
      env:
        CA_PROVIDER: Citadel
        CA_ADDR: "istio-citadel.{{ $namespaces.network }}.svc:8060"
        VALID_TOKEN: true
    security:  # citadel is part of istio-pilot
      citadelHealthCheck: true
    sidecarInjectorWebhook:  # part of control plane (istiod)
      enabled: true
{{- else }}
- name: {{ $releases.istio.base }}
  namespace: {{ $namespaces.network }}
  chart: {{ $istioChartManifestBase }}/base
  values:
  - {{ $istioChartManifestBase }}/global.yaml
  - global:
      <<: *istioGlobal
- name: {{ $releases.istio.control }}
  namespace: {{ $namespaces.network }}
  chart: {{ $istioChartManifestBase }}/istio-control/istio-discovery
  needs:
  - {{ $namespaces.network }}/{{ $releases.istio.base }}
  values:
  - {{ $istioChartManifestBase }}/global.yaml
  - global:
      <<: *istioGlobal
      <<: *istioControl
- name: {{ $releases.istio.gateway.egress }}
  namespace: {{ $namespaces.network }}
  chart: {{ $istioChartManifestBase }}/gateways/istio-egress
  needs:
  - {{ $namespaces.network }}/{{ $releases.istio.control }}
  values:
  - {{ $istioChartManifestBase }}/global.yaml
  - global:
      <<: *istioGlobal
    gateways:
      istio-egressgateway:
        <<: *istioEgress
- name: {{ $releases.istio.gateway.ingress }}
  namespace: {{ $namespaces.network }}
  chart: {{ $istioChartManifestBase }}/gateways/istio-ingress
  needs:
  - {{ $namespaces.network }}/{{ $releases.istio.control }}
  values:
  - {{ $istioChartManifestBase }}/global.yaml
  - global:
      <<: *istioGlobal
    gateways:
      istio-ingressgateway:
        <<: *istioIngress
- name: {{ $releases.istio.policy }}
  namespace: {{ $namespaces.network }}
  chart: {{ $istioChartManifestBase }}/istio-policy
  needs:
  - {{ $namespaces.network }}/{{ $releases.istio.control }}
  values:
  - {{ $istioChartManifestBase }}/global.yaml
  - global:
      <<: *istioGlobal
    <<: *istioMixer
- name: {{ $releases.istio.telemetry.grafana }}
  namespace: {{ $namespaces.network }}
  chart: {{ $istioChartManifestBase }}/istio-telemetry/grafana
  needs:
  - {{ $namespaces.network }}/{{ $releases.istio.control }}
  values:
  - {{ $istioChartManifestBase }}/global.yaml
  - global:
      <<: *istioGlobal
- name: {{ $releases.istio.telemetry.kiali }}
  namespace: {{ $namespaces.network }}
  chart: {{ $istioChartManifestBase }}/istio-telemetry/kiali
  needs:
  - {{ $namespaces.network }}/{{ $releases.istio.control }}
  values:
  - {{ $istioChartManifestBase }}/global.yaml
  - global:
      <<: *istioGlobal
    <<: *istioKiali
{{- end }}
# https://github.com/coreos/prometheus-operator/issues/2502
# https://github.com/istio/installer/pull/71
- name: {{ $releases.istio.telemetry.prometheusOperator }}
  namespace: {{ $namespaces.network }}
  chart: {{ $istioChartManifestBase }}/istio-telemetry/prometheusOperator
  needs:
  - {{ $namespaces.monitoring }}/{{ $releases.prometheusOperator }}
{{- if semverCompare "<1.6" $versions.istio }}
  - {{ $namespaces.network }}/{{ $releases.istio.old }}
{{- else }}
  - {{ $namespaces.network }}/{{ $releases.istio.control }}
{{- end }}
  values:
  - {{ $istioChartManifestBase }}/global.yaml
  - global:
      <<: *istioGlobal

# storage components
- name: {{ $releases.openebs }}
  namespace: {{ $namespaces.storage }}
  chart: stable/openebs
  values:  # ref: https://openebs.github.io/charts/openebs-lite-helm-values.yaml
  - fullnameOverride: {{ $releases.openebs | quote }}
    image:  # hopefully a temporary state of affairs
      repository: docker.io/
    analytics:
      enabled: false
    release:
      version: {{ $versions.openebs }}
    apiserver:  # not needed for just local PV
      <<: *openebsLVP
      <<: *openebsTag
    provisioner:  # not needed for just local PV
      <<: *openebsLVP
      <<: *openebsTag
    localprovisioner:
      enabled: true
      <<: *openebsTag
    snapshotOperator:  # not needed for just local PV
      <<: *openebsLVP
      controller:
        <<: *openebsTag
      provisioner:
        <<: *openebsTag
    webhook:  # not needed for just local PV
      <<: *openebsLVP
      <<: *openebsTag
    jiva:
      <<: *openebsTag
    cstor:
      pool:
        <<: *openebsTag
      poolMgmt:
        <<: *openebsTag
      target:
        <<: *openebsTag
      volumeMgmt:
        <<: *openebsTag
    helper:
      <<: *openebsTag
    policies:
      monitoring:
        <<: *openebsTag
    ndmOperator:
      <<: *openebsNdmTag
    ndm:
      <<: *openebsNdmTag
      filters:
        excludePaths: "/dev/sd,/dev/vd,fd0,sr0,/dev/ram,/dev/dm-,/dev/md,/dev/zram{{ $openebsOmitLoopDevs }}"
        includePaths: "/dev/loop"
  hooks:
  - events: ["postsync"]
    command: "/bin/sh"
    args:
    - "-xec"
    - |
      for i in $(kubectl get sc -o jsonpath='{.items[?(@.metadata.annotations.storageclass\.kubernetes\.io/is-default-class=="true")].metadata.name}'); do
        kubectl annotate sc ${i} storageclass.kubernetes.io/is-default-class-
      done
      kubectl apply -f- <<EOF
      apiVersion: storage.k8s.io/v1
      kind: StorageClass
      provisioner: openebs.io/local
      volumeBindingMode: WaitForFirstConsumer
      reclaimPolicy: Delete
      metadata:
        name: openebs-hostpath
        annotations:
          storageclass.kubernetes.io/is-default-class: "true"
          openebs.io/cas-type: local
          cas.openebs.io/config: |
            #hostpath type will create a PV by
            # creating a sub-directory under the
            # BASEPATH provided below.
            - name: StorageType
              value: "hostpath"
            #Specify the location (directory) where
            # where PV(volume) data will be saved.
            # A sub-directory with pv-name will be
            # created. When the volume is deleted,
            # the PV sub-directory will be deleted.
            #Default value is /var/openebs/local
            - name: BasePath
              value: "/var/openebs/local/"
      #---
      #apiVersion: storage.k8s.io/v1
      #kind: StorageClass
      #provisioner: openebs.io/local
      #volumeBindingMode: WaitForFirstConsumer
      #reclaimPolicy: Delete
      #metadata:
      #  name: openebs-device
      #  annotations:
      #    openebs.io/cas-type: local
      #    cas.openebs.io/config: |
      #      #device type will create a PV by
      #      # issuing a BDC and will extract the path
      #      # values from the associated BD.
      #      - name: StorageType
      #        value: "device"
      EOF
- name: {{ $releases.minio }}
  namespace: {{ $namespaces.storage }}
  chart: stable/minio
  needs:
  - {{ $namespaces.storage }}/{{ $releases.openebs }}
  values:
  - fullnameOverride: {{ $releases.minio | quote }}
    accessKey: {{ $minio.accessKey | quote }}
    secretKey: {{ $minio.secretKey | quote }}
    service:
      port: {{ $minio.servicePort }}
      clusterIP: None
    persistence:  # parameterize based on presence of OpenEBS
      enabled: false
    defaultBucket:
      name: {{ $minio.defaultBucket | quote }}
      enabled: true
  hooks:
  - events: ["postsync"]
    command: "/bin/sh"
    args:
    - "-xec"
    - |
      MC_NAME="mc-${RANDOM}"
      kubectl -n {{ $namespaces.storage }} apply -f- <<EOF
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: ${MC_NAME}
      spec:
        replicas: 1
        selector:
          matchLabels:
            app: ${MC_NAME}
        template:
          metadata:
            labels:
              app: ${MC_NAME}
          spec:
            containers:
            - name: mc
              image: minio/mc
              command: ['/bin/sh', '-c', 'while true; do sleep 86400; done']
      EOF
      until kubectl -n {{ $namespaces.storage }} wait --for condition=available deploy ${MC_NAME}; do sleep 1; done 2>/dev/null
      kubectl -n {{ $namespaces.storage }} exec $(kubectl -n {{ $namespaces.storage }} get pods -o jsonpath="{.items[?(@.metadata.labels.app==\"${MC_NAME}\")].metadata.name}" | awk '{print $1}') -- /bin/sh -xc "mc config host add minio http://{{ $releases.minio }}.{{ $namespaces.storage }}.svc:{{ $minio.servicePort }} {{ $minio.accessKey }} {{ $minio.secretKey }}"
      echo "MinIO is available under http://{{ $releases.minio }}.{{ $namespaces.storage }}.svc:{{ $minio.servicePort }} with access key \"{{ $minio.accessKey }}\", secret key \"{{ $minio.secretKey }}\" and default bucket \"{{ $minio.defaultBucket }}\"."
- name: {{ $releases.patroni }}
  namespace: {{ $namespaces.storage }}
  chart: ./zer0def-charts/incubator/patroni
  needs:
  - {{ $namespaces.storage }}/{{ $releases.openebs }}
  values:
  - fullnameOverride: {{ $releases.patroni | quote }}
    replicaCount: 1
    image:
      #repository: registry.opensource.zalan.do/acid/spilo-10
      #tag: 1.5-p5
      #repository: registry.opensource.zalan.do/acid/spilo-11
      #tag: 1.6-p1
      repository: registry.opensource.zalan.do/acid/spilo-12
      tag: 1.6-p3
    pgbouncer:
      replicaCount: 1
    databases:
    - name: {{ $harbor.db.core.name | quote }}
      user: {{ $harbor.db.core.user | quote }}
      pass: {{ $harbor.db.core.pass | quote }}
    - name: {{ $harbor.db.clair.name | quote }}
      user: {{ $harbor.db.core.user | quote }}
      pass: {{ $harbor.db.core.pass | quote }}
      #user: {{ $harbor.db.clair.user | quote }}
      #pass: {{ $harbor.db.clair.pass | quote }}
    - name: {{ $harbor.db.notaryServer.name | quote }}
      user: {{ $harbor.db.core.user | quote }}
      pass: {{ $harbor.db.core.pass | quote }}
      #user: {{ $harbor.db.notaryServer.user | quote }}
      #pass: {{ $harbor.db.notaryServer.pass | quote }}
    - name: {{ $harbor.db.notarySigner.name | quote }}
      user: {{ $harbor.db.core.user | quote }}
      pass: {{ $harbor.db.core.pass | quote }}
      #user: {{ $harbor.db.notarySigner.user | quote }}
      #pass: {{ $harbor.db.notarySigner.pass | quote }}
    env:
      ALLOW_NOSSL: "true"
    spiloConfiguration:
      bootstrap:
        initdb:
        - data-checksums
- name: {{ $releases.redis }}
  namespace: {{ $namespaces.storage }}
  chart: stable/redis-ha
  needs:
  - {{ $namespaces.storage }}/{{ $releases.openebs }}
  values:
  - fullnameOverride: {{ $releases.redis | quote }}
    hardAntiAffinity: false
    image:
      tag: 5-alpine
    haproxy:  # required for harbor-jobservice to do proper init, but also generally a decent idea
      enabled: true
      stickyBalancing: true
      hardAntiAffinity: false
      readOnly:
        enabled: true
    #auth: true
    #redisPassword: {{ $redisPassword }}
- name: {{ $releases.harbor }}
  namespace: {{ $namespaces.storage }}
  chart: harbor/harbor
  version: {{ $harbor.chartVersion }}
  needs:
  - {{ $namespaces.storage }}/{{ $releases.minio }}
  - {{ $namespaces.storage }}/{{ $releases.patroni }}
  - {{ $namespaces.storage }}/{{ $releases.redis }}
  values:
  - nameOverride: {{ $releases.harbor | quote }}
    # default admin username for Harbor is `admin`
    harborAdminPassword: {{ $harbor.adminPassword | quote }}
    externalURL: "https://{{ $harbor.coreHostname }}"
    #externalURL: "https://{{ $releases.harbor }}-{{ $releases.harbor }}-core.{{ $namespaces.storage }}.svc"
    expose:  # by default, service is `ingress`
      #type: nodePort
      #nodePort:
      #  ports:
      #    http:
      #      nodePort: {{ $harbor.httpNodePort }}
      ingress:
        annotations:  # be sure to suffix registry with `:80` when pushing images
          ingress.kubernetes.io/ssl-redirect: "false"
          nginx.ingress.kubernetes.io/ssl-redirect: "false"
        hosts:
          core: {{ $harbor.coreHostname }}
      tls:
        enabled: true
    persistence:
      imageChartStorage:
        disableredirect: true
        type: s3
        s3:
          accesskey: {{ $minio.accessKey | quote }}
          secretkey: {{ $minio.secretKey | quote }}
          bucket: {{ $minio.defaultBucket | quote }}
          # if using insecure object storage endpoints, you need to prefix it with `http://` protocol for chartmuseum to not barf
          secure: false
          regionendpoint: "http://minio.{{ $namespaces.storage }}.svc:{{ $minio.servicePort }}"
    database:
      type: external
      external:
        host: {{ $releases.patroni }}.{{ $namespaces.storage }}.svc
        username: {{ $harbor.db.core.user | quote }}
        password: {{ $harbor.db.core.pass | quote }}
        coreDatabase: {{ $harbor.db.core.name | quote }}
        clairDatabase: {{ $harbor.db.clair.name | quote }}
        notaryServerDatabase: {{ $harbor.db.notaryServer.name | quote }}
        notarySignerDatabase: {{ $harbor.db.notarySigner.name | quote }}
        #sslmode: require
    redis:
      type: external
      external:
        host: {{ $releases.redis }}-haproxy.{{ $namespaces.storage }}.svc
        #password: {{ $redisPassword | quote }}
    nginx:
      <<: *harborVersion
    portal:
      <<: *harborVersion
    core:
      <<: *harborVersion
    jobservice:
      <<: *harborVersion
      jobLogger: database
    registry:
      registry:
        <<: *harborVersion
      controller:
        <<: *harborVersion
    chartmuseum:
      <<: *harborVersion
    clair:
      clair:
        <<: *harborVersion
      adapter:
        <<: *harborVersion
    trivy:
      <<: *harborVersion
    notary:
      server:
        <<: *harborVersion
      signer:
        <<: *harborVersion

# monitoring
- name: {{ $releases.thanos }}
  namespace: {{ $namespaces.monitoring }}
  chart: banzaicloud/thanos
  needs:
  - {{ $namespaces.storage }}/{{ $releases.minio }}
  values:
  - fullnameOverride: {{ $releases.thanos | quote }}
    objstoreSecretOverride: {{ $thanosObjstoreConfig.secret | quote }}
    image:
      tag: 'v{{ $versions.thanos }}'
    compact:
      retentionResolutionRaw: 3d
      retentionResolution5m: 16d
      retentionResolution1h: 28d
- name: {{ $releases.prometheusOperator }}
  namespace: {{ $namespaces.monitoring }}
  chart: stable/prometheus-operator
  needs:
  - {{ $namespaces.monitoring }}/{{ $releases.thanos }}
  values:
  - fullnameOverride: {{ $releases.prometheusOperator | quote }}
    prometheus:
      prometheusSpec:
        podMetadata:
          labels:
            prometheus: self
        #serviceMonitorNamespaceSelector: {}
        serviceMonitorSelector:
          matchLabels: {}  # match *ALL* ServiceMonitors on an *empty* set of labels
        #podMonitorNamespaceSelector: {}
        podMonitorSelector:
          matchLabels: {}  # match *ALL* PodMonitors on an *empty* set of labels
        retention: 3h
        thanos:  # https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#thanosspec
          version: v{{ $versions.thanos }}
          objectStorageConfig:
            key: {{ $thanosObjstoreConfig.filename }}
            name: {{ $thanosObjstoreConfig.secret }}
    grafana:
      sidecar:
        datasources:
          defaultDatasourceEnabled: false
      additionalDataSources:
      - name: Thanos
        type: prometheus
        url: "http://thanos-query-http.{{ $namespaces.monitoring }}.svc:10902/"
        access: proxy
        isDefault: true
- name: {{ $releases.prometheusAdapter }}
  namespace: {{ $namespaces.monitoring }}
  chart: stable/prometheus-adapter
  needs:
  - {{ $namespaces.monitoring }}/{{ $releases.prometheusOperator }}
  values:
  - image:
      repository: directxman12/k8s-prometheus-adapter
      tag: v{{ $versions.prometheusAdapter }}
    prometheus:
      url: "http://{{ $releases.prometheusOperator }}-prometheus.{{ $namespaces.monitoring }}.svc"
    # https://github.com/DirectXMan12/k8s-prometheus-adapter/blob/master/docs/config.md
    # use autoscaling/v2beta[12] HorizontalPodAutoscaler
    rules: {}

# serverless
- name: {{ $releases.kubeless }}
  namespace: {{ $namespaces.serverless }}
  # should be installing upstream incubator/kubeless chart, but it's shit
  chart: ./zer0def-charts/incubator/kubeless
  values:
  - nameOverride: {{ $releases.kubeless | quote }}
    rbac:
      create: true
    controller:
      deployment:
        functionController:
          image:
            tag: v1.0.6
        httpTriggerController:
          image:
            tag: v1.0.2
        cronJobTriggerController:
          image:
            tag: v1.0.2
    kafkaTrigger:
      deployment:
        image:
          tag: v1.0.2
    config:
      functionsNamespace: {{ $namespaces.serverlessFunctions }}
    ui:
      enabled: true
      service:
        type: ClusterIP
